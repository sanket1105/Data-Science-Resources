{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the linear regression code form the same directory\n",
    "\n",
    "https://www.geeksforgeeks.org/saving-a-machine-learning-model/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "\n",
    "df = pd.read_csv(\"../Datasets/Homeprices.csv\")\n",
    "\n",
    "## Linear Regression Model\n",
    "model_reg = linear_model.LinearRegression()\n",
    "model_reg.fit(df[['area']],df['price'])\n",
    "## since linear equation is of form: Y = weight * x + bias\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now using the Pickle method to store the model\n",
    "It will automatically create a file in the directory and you just need to call the file name so as to make the model run.  No need to write the code again and again for the new algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "## linear reg model is saved as model_reg\n",
    "## so we will dumping the same model in model_pickel file\n",
    "## your model will get saved in the current directory path\n",
    "\n",
    "## dump to save the model in the file\n",
    "## load to open the model\n",
    "\n",
    "with open(\"model_pickle\",'wb') as f:\n",
    "    pickle.dump(model_reg,f)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model_pickle\",'rb') as f:\n",
    "    mp = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([627849.51644569])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## just load the pickle library and use the predict method\n",
    "mp.predict([[5000]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You can do this also:\n",
    "\n",
    "->Save the trained model as a pickle string.]\n",
    "\n",
    "saved_model = pickle.dumps(knn)\n",
    " \n",
    "->Load the pickled model\n",
    "\n",
    "knn_from_pickle = pickle.loads(saved_model)\n",
    " \n",
    "->Use the loaded pickled model to make predictions\n",
    "\n",
    "knn_from_pickle.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joblib does the same work but when you have many numpy arrays in your model, use joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([627849.51644569])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model_reg,\"model_joblib\")\n",
    "\n",
    "model = joblib.load(\"model_joblib\")\n",
    "model.predict([[5000]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "630138.5219477906"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_\n",
    "## you can get the intercept and coeff values of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets see the running time diff between pickel and joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " time taken to load pickle model is:  0.0009968280792236328\n",
      " time taken to load joblib model is:  0.000997304916381836\n"
     ]
    }
   ],
   "source": [
    "## joblib loads the file in minimal time\n",
    "\n",
    "from time import time\n",
    "\n",
    "t1 = time()\n",
    "with open(\"model_pickle\",'rb') as f:\n",
    "    mp = pickle.load(f)\n",
    "k = float(time() - t1)\n",
    "print(\" time taken to load pickle model is: \", k)    \n",
    "\n",
    "t2 = time()\n",
    "joblib.load('model_joblib')\n",
    "k2 = float(time() - t2)\n",
    "print(\" time taken to load joblib model is: \", k2)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6b6e8e5f654a8e9bb9e69623dd15cf09cd0bf1a8f120d3fdbf2d2c9cdde81e19"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('gpu': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
